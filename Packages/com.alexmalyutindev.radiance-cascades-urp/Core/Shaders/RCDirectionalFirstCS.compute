#pragma kernel RenderCascade
#pragma kernel MergeCascade

#include "Common.hlsl"

float _ProbeSize;
RWTexture2D<float4> _OutCascade;

// Cascade Layout
// Rows - depth angled rays
// Columns - projection angled rays
// ._______________________________.
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|

static const int2 Ranges[] =
{
    int2(0, 2),
    int2(2, 4),
    int2(4, 8),
    int2(8, 16),
    int2(16, 32),
    int2(32, 64),
    int2(64, 128),
    int2(128, 256),
    int2(256, 512),
};

static const int2 Ranges2[] =
{
    int2(0, 2),
    int2(2, 8),
    int2(8, 32),
    int2(32, 128),
    int2(128, 512),
};

static const int2 Ranges3[] =
{
    int2(0, 3),
    int2(3, 8),
    int2(8, 16),
    int2(16, 28),
    int2(28, 42),
};

static const int IntLog2[] = {
    1, 2, 4, 8, 16, 32,
};

// #define DEBUG

float3 TransformWorldToScreenSpace(float3 positionWS)
{
    float4 positionCS = TransformWorldToHClip(positionWS);
    positionCS.xyz /= positionCS.w;
    positionCS.xy = mad(positionCS.xy, float2(0.5f, -0.5f), float2(0.5f, 0.5f));
    return positionCS.xyz;
}

[numthreads(8,8,1)]
void RenderCascade(uint3 id : SV_DispatchThreadID)
{
    uint2 coords = id.xy;
    if (any(coords > uint2(_CascadeBufferSize.xy)))
    {
        return;
    }

    // TODO: Add padding!
    float cascadeLevel = (coords.y + 1) * _CascadeBufferSize.w;
    cascadeLevel = floor(-log2(cascadeLevel));
    // NOTE: Hardcode 5 Cascades.
    if (cascadeLevel > 5)
    {
        _OutCascade[coords] = float4(0, 0.0f, 0.0f, 0.0f);
        return;
    }

    const float cascadeFactor = pow(2.0f, cascadeLevel);
    const float projRays = 8.0f * cascadeFactor;
    const float depthRays = floor(4.0f * cascadeFactor * 2.0f);

    // NOTE: 8 proj x 4 depth rays in Cascade0
    float deltaAngle = TWO_PI * pow(0.5f, cascadeLevel) * 0.125f; // 1/8
    float2 angleId;
    angleId.x = floor(coords.x * projRays * _CascadeBufferSize.z);
    angleId.y = fmod(floor((1.0f - (coords.y + 1) * _CascadeBufferSize.w) * depthRays), 4);
    float angleX = (angleId.x + 0.5f) * deltaAngle;

    // TODO: Depth rays angle!
    // TODO: I can spawn less threads, cus depth rays can be done in simultaneously (one pixel in depth buffer)
    // and then i should write then into four pixels in cascade. Potentially, it should reduce time by 4.
    float angleD = (angleId.y - 1.5f) * HALF_PI * 0.25f;

    // TODO: Remove separate thread to depth rays, cast 4 rays in one thread.
    // if (angleId.y > 2.5f)
    // {
    //     _OutCascade[coords] = float4(0, 0.0f, 0.0f, 0.0f);
    //     return;
    // }

    if (frac((1.0f - coords.y * _CascadeBufferSize.w) * depthRays) == 0 ||
        frac(coords.x * projRays * _CascadeBufferSize.z) == 0
    )
    {
        // NOTE: Horizontal black line to separate cascades.
        _OutCascade[coords] = float4(0.0f, 0.0f, 0.0f, 0.0f);
        return;
    }


    // TODO: Calculate probe center!
    float2 probeCenterUV = frac(coords * _CascadeBufferSize.zw * float2(projRays, depthRays));
    float2 probesCount = floor(_CascadeBufferSize.xy / float2(projRays, depthRays));
    probeCenterUV = (floor(probeCenterUV * probesCount) - 0.5) / (probesCount - 1.0f);

    float probeDepth = SAMPLE_DEPTH_TEXTURE_LOD(_DepthTexture, sampler_PointClamp, probeCenterUV, 0);

    if (probeDepth == UNITY_RAW_FAR_CLIP_VALUE)
    {
        _OutCascade[coords] = float4(0.0f, 0.0f, 0.0f, 1.0f);
        return;
    }

    float3 probeCenterWS = GetPositionWS(probeCenterUV, probeDepth);
    float3 viewDirectionWS = normalize(probeCenterWS - _WorldSpaceCameraPos);
    #if 0 // NOTE: Horizontal plane snapping
    probeCenterWS = Intersect(float3(0.0f, 0.5f, 0.0f), float3(0.0f, 1.0f, 0.0f), _WorldSpaceCameraPos, viewDirectionWS);
    #endif
    probeCenterWS -= viewDirectionWS * 0.2f;

    // TODO: Fix directionWS.z, wrong scaling
    float3 directionWS = float3(0.0f, lerp(-0.5f, 0.5f, angleId.y * 0.33334f), 0.0f);
    sincos(angleX, directionWS.z, directionWS.x);
    directionWS = normalize(directionWS);

    int2 range = Ranges[cascadeLevel];
    
    float rayScale = 0.05f;
    float3 rayOriginWS = probeCenterWS + directionWS * rayScale * range.x;
    float3 rayEndWS = rayOriginWS + directionWS * rayScale * range.y;

    float3 rayOriginVS = TransformWorldToView(rayOriginWS);
    float3 rayEndVS = TransformWorldToView(rayEndWS);

    float3 rayOriginCS = TransformWorldToScreenSpace(rayOriginWS);
    float3 rayEndCS = TransformWorldToScreenSpace(rayEndWS);

    float stepsCount = length((rayEndCS.xy - rayOriginCS.xy) * _ColorTexture_TexelSize.zw) * 0.25f;
    stepsCount = min(stepsCount, 50);
    stepsCount = max(2, stepsCount);

    float4 color = float4(0.0f, 0.0f, 0.0f, 1.0f);

    UNITY_LOOP
    for (float i = 0; i < stepsCount; i++)
    {
        // TODO: Use DDA for ray marching.
        float3 rayWS = lerp(rayOriginWS, rayEndWS, i / (stepsCount - 1.0f));
        float3 ray = TransformWorldToScreenSpace(rayWS);
        if (any(ray.xy < 0 || 1 < ray.xy)) break;

        // TODO: Use Hi-Z Buffer.
        float depth = SAMPLE_DEPTH_TEXTURE_LOD(_DepthTexture, sampler_LinearClamp, ray.xy, 0);
        // TODO: Compare depth in VS.
        // To find ray.z in ClipSpace i should transform it in ViewSpace then add needed component
        // I need to compensate perspective distortion. Rays shot in camera direction will be smaller
        // than ray out of camera.
        float linearDepth = LinearEyeDepth(depth, _ZBufferParams);

        // TODO: Compare depth for 4 depth rays.
        bool test = depth > ray.z && depth < ray.z + 0.0005f;
        
        if (test)
        {
            color.rgb = SAMPLE_TEXTURE2D_LOD(_ColorTexture, sampler_LinearClamp, ray.xy, 0);
            color.a = 0.0f;
            break;
        }
    }

    _OutCascade[coords] = color;
}


float _CascadeLevel; // UpperCascadeLevel

float _LowerCascadeBottomCoord;
float _UpperCascadeBottomCoord;

float _LowerCascadeAnglesCount;
float _UpperCascadeAnglesCount;

RWTexture2D<float4> _LowerCascade;
Texture2D<float4> _UpperCascade;

float4 SampleUpperCascade(float2 uv)
{
    float4 radiance = SAMPLE_TEXTURE2D_LOD(_UpperCascade, sampler_LinearClamp, uv, 0);
    // float4 radiance = SAMPLE_TEXTURE2D_LOD(_UpperCascade, sampler_PointClamp, uv, 0);
    return radiance;
}

[numthreads(8,8,1)]
void MergeCascade(uint3 id : SV_DispatchThreadID)
{
    float2 uv = float2(id.xy + 0.5f) / (_CascadeBufferSize.xy - 1.0f);
    float lowerAngleId = floor(uv.x * _LowerCascadeAnglesCount);

    // NOTE: This *0.5f is subpixel for bilinear sampling of UpperCascade
    float2 upperUVLeft = uv * 0.5f + float2(lowerAngleId / _UpperCascadeAnglesCount,
                                            _UpperCascadeBottomCoord * _CascadeBufferSize.w);
    float2 upperUVRight = upperUVLeft + float2(0.5f / _LowerCascadeAnglesCount, 0.0f);

    int2 lowerCoords = id.xy + int2(0, _LowerCascadeBottomCoord);
    float4 radiance = _LowerCascade[lowerCoords];

    // float4 test = SAMPLE_TEXTURE2D_LOD(_UpperCascade, sampler_LinearClamp, upperUVLeft, 0);
    // _LowerCascade[lowerCoords] = test;
    // return;

    if (radiance.a < 0.1f)
    {
        return;
    }

    float4 upperRadianceLeft = SampleUpperCascade(upperUVLeft);
    float4 upperRadianceRight = SampleUpperCascade(upperUVRight);

    float4 upperRadiance = (upperRadianceLeft + upperRadianceRight) * 0.5f;

    radiance.rgb += upperRadiance.rgb * radiance.a;
    radiance.a *= upperRadiance.a;

    _LowerCascade[lowerCoords] = radiance;
}
