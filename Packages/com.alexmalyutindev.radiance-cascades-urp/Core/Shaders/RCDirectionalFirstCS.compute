#pragma kernel RenderCascade
#pragma kernel MergeCascade

#include "Common.hlsl"

float _ProbeSize;
RWTexture2D<float4> _OutCascade;

// Cascade Layout
// Rows - depth angled rays
// Columns - projection angled rays
// ._______________________________.
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|
// |   ⬈   |   ⬉   |   ⬋   |   ⬊   |
// |_______|_______|_______|_______|

static const int2 Ranges[] =
{
    // int2(0, 2),
    int2(2, 4),
    int2(4, 8),
    int2(8, 16),
    int2(16, 32),
    int2(32, 64),
    int2(64, 128),
    int2(128, 256),
    int2(256, 512),
};

[numthreads(8,8,1)]
void RenderCascade(uint3 id : SV_DispatchThreadID)
{
    uint2 coords = id.xy;
    if (any(coords > uint2(_CascadeBufferSize.xy)))
    {
        return;
    }

    // TODO: Add padding!
    float cascadeLevel = coords.y * _CascadeBufferSize.w;
    cascadeLevel = floor(-log2(cascadeLevel));
    // NOTE: Hardcode 5 Cascades.
    if (cascadeLevel > 5)
    {
        return;
    }

    float cascadeFactor = pow(2.0f, cascadeLevel);
    float projRays = 8.0f * cascadeFactor;
    const float depthRays = 4.0f * cascadeFactor * 2.0f;

    // NOTE: 8 proj x 4 depth rays in Cascade0
    float deltaAngle = TWO_PI * pow(0.5f, cascadeLevel) * 0.125f; // 1/8
    float2 angleId = floor(coords * _CascadeBufferSize.zw * float2(projRays, depthRays));
    float angleX = (angleId.x + 0.5f) * deltaAngle;

    // TODO: Remove separate thread to depth rays, cast 4 rays in one thread.
    if (angleId.y % 4.0f < 2.5f)
    {
        // _OutCascade[coords] = float4(0, 0.5f, 0.0f, 1.0f);
        // return;
    }

    // TODO: Depth rays angle!
    // TODO: I can spawn less threads, cus depth rays can be done in simultaneously (one pixel in depth buffer)
    // and then i should write then into four pixels in cascade. Potentially, it should reduce time by 4.
    float angleD = (angleId.y - 1.5f) * HALF_PI * 0.25f;


    // TODO: Calculate probe center!
    float2 rayOrigin = frac(coords * _CascadeBufferSize.zw * float2(projRays, depthRays));

    float depth0 = SAMPLE_DEPTH_TEXTURE_LOD(_DepthTexture, sampler_PointClamp, rayOrigin, 0);

    #if 1 // NOTE: Horizontal plane snapping
    float3 positionWS = GetPositionWS(rayOrigin, depth0);
    float3 viewDirectionWS = normalize(positionWS - _WorldSpaceCameraPos);
    positionWS = Intersect(0.0f, float3(0, 1, 0), _WorldSpaceCameraPos, viewDirectionWS);
    positionWS -= viewDirectionWS * 0.1f;
    float4 positionCS = TransformWorldToHClip(positionWS);
    depth0 = positionCS.z / positionCS.w;
    #endif

    float2 direction;
    sincos(angleX, direction.y, direction.x);
    // TODO: Ray scale?
    direction *= min(_ColorTexture_TexelSize.x, _ColorTexture_TexelSize.y) * 1.0f;
    // direction *= _ColorTexture_TexelSize.xy;

    float depth0Thick = depth0 + 0.001f;

    float4 color = float4(0.0f, 0.0f, 0.0f, 1.0f);
    int2 range = Ranges[cascadeLevel];
    range = CalculateRange(cascadeLevel);

    UNITY_LOOP
    for (int i = range.x; i < range.y; i++)
    {
        float2 ray = rayOrigin + direction * i;
        if (any(ray < 0.0f || 1.0f < ray)) break;

        float depth = SAMPLE_DEPTH_TEXTURE_LOD(_DepthTexture, sampler_PointClamp, ray, 0);

        // TODO: Compare depth for 4 depth rays.
        // To find ray.z in ClipSpace i should transform it in ViewSpace then add needed component
        // I need to compensate perspective distortion. Rays shot in camera direction will be smaller
        // than ray out of camera.
        if (depth0 < depth && depth < depth0Thick)
        {
            color.rgb = SAMPLE_TEXTURE2D_LOD(_ColorTexture, sampler_LinearClamp, ray, 0).rgb;
            color.a = 0.0f;
            break;
        }
    }

    // color += float4(0, cascadeLevel * 0.1f, id.x * _CascadeBufferSize.z, 0);
    _OutCascade[coords] = color;

    // float l = angleX * INV_TWO_PI;
    // float3 c0 = lerp(float3(1, 0, 0), float3(0, 1, 0), l);
    // float3 c1 = lerp(float3(0, 1, 0), float3(0, 0, 1), l);
    // float3 c2 = lerp(c0, c1, l);
    // _OutCascade[coords] = float4(c2 * 0.5f, 1.0f);
}


// UpperCascadeLevel
float _CascadeLevel;
RWTexture2D<float4> _LowerCascade;
Texture2D<float4> _UpperCascade;

float4 SampleUpperCascade(float2 uv)
{
    float4 radiance = SAMPLE_TEXTURE2D_LOD(_UpperCascade, sampler_LinearClamp, uv, 0);
    // float4 radiance = SAMPLE_TEXTURE2D_LOD(_UpperCascade, sampler_PointClamp, uv, 0);
    return radiance;
}

[numthreads(8,8,1)]
void MergeCascade(uint3 id : SV_DispatchThreadID)
{
    if (float(id.x) > _CascadeBufferSize.x)
    {
        return;
    }

    // TODO: Move this staff to the CPU side
    float lowerCascadeUVBottom = pow(2, -_CascadeLevel);
    float upperCascadeUVBottom = pow(2, -(_CascadeLevel + 1));
    const float lowerAnglesCount = 8.0f * pow(2.0f, _CascadeLevel - 1.0f);

    // BUG: Wrong y offset?
    int2 lowerCoords = id.xy + int2(0, lowerCascadeUVBottom * _CascadeBufferSize.y);

    // NOTE: This *0.5f is subpixel for bilinear sampling of UpperCascade
    float2 uv = float2(id.xy + 0.5f) / (_CascadeBufferSize.xy - 1.0f);
    float2 upperUVLeft = uv * 0.5f + float2(floor(uv.x * lowerAnglesCount) / lowerAnglesCount, upperCascadeUVBottom);
    float2 upperUVRight = upperUVLeft + float2(0.5f / lowerAnglesCount, 0.0f);

    float4 radiance = _LowerCascade[lowerCoords];
    if (radiance.a < 0.5f) return;

    float4 upperRadianceLeft = SampleUpperCascade(upperUVLeft);
    float4 upperRadianceRight = SampleUpperCascade(upperUVRight);

    float4 upperRadiance = (upperRadianceLeft + upperRadianceRight) * 0.5f;

    radiance.rgb += upperRadiance.rgb * radiance.a;
    radiance.a *= upperRadiance.a;

    _LowerCascade[lowerCoords] = radiance;
}
